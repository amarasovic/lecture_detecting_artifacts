{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef54e3f",
   "metadata": {},
   "source": [
    "# Detecting Annotation Artifacts with Local Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c2999",
   "metadata": {},
   "source": [
    "- Add a definition of data artifact \n",
    "\n",
    "- Introduce a controled example from Section 6.1. here: https://arxiv.org/abs/2107.00323\n",
    "\n",
    "- Re-iterate what is the methodology for artifact discovery, Section 4 above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed95189",
   "metadata": {},
   "source": [
    "## Task and Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32c0e43",
   "metadata": {},
   "source": [
    "We will demonstrate how to detect annotation artifacts in the context of **binary sentiment classification** of movie reviews, i.e., classifying a given movie review as positive or negative. One commonly used dataset for this task is the [IMDB dataset](http://ai.stanford.edu/~amaas/data/sentiment/). A useful library for accessing NLP datasets is [datasets by Huggingface](https://huggingface.co/docs/datasets/) ðŸ¤—. We can load the IMDB dataset using `datasets` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ede449c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca8ec5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77a9d89d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/Users/anam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb124aaa643345e2a6e32598b95abd7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864bc438",
   "metadata": {},
   "source": [
    "This loads a `DatasetDict` object which you can index into to view an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca939ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e0c57f",
   "metadata": {},
   "source": [
    "You can select an example randomly like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c99c6cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"IN LOVING MEMORY OF DAVID TOMLINSON (1917-2000)<br /><br />When I watched this movie for the first time I was 4 years old and I got fascinated by this story of witches in the 2nd World War. The scene, which impressed me the most, was the fight between the Nazi soldiers and the medieval army. It was exceptional to see this army without a body walk to fight the astonished singing their march. This movie is fantastic, from the trip to Portobello Road (which became to me the most fantastic place of London) to the journey to Naboomboo. Angela Lansbury and David Tomlinson are really a fantastic couple. She is always great, it seems the good aunt of a family and David with his always astonished face is her great co-protagonist. we'll miss him a lot.\",\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].shuffle().select(range(1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd72e43",
   "metadata": {},
   "source": [
    "`'label': 0` stands for `negative`, and `1` for `positive`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed5a2e5",
   "metadata": {},
   "source": [
    "## Annotation Artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76c2e43",
   "metadata": {},
   "source": [
    "It has been reported that neural models solely use the numberical rating at the end of the review instead of reading and understanding the semantics of the review. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab145cf",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "444f3762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"aychang/roberta-base-imdb\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "nlp = pipeline(\"sentiment-analysis\", model=model_name, tokenizer=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7422e354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'neg', 'score': 0.9984696507453918}, {'label': 'pos', 'score': 0.9991361498832703}]\n"
     ]
    }
   ],
   "source": [
    "classifier = nlp([\"I didn't really like it because it was so terrible.\", \"I love how easy it is to watch and get good results.\"])\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d63eb27",
   "metadata": {},
   "source": [
    "## Gradient-Based Highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55bce4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-25 18:36:51,548 - ERROR - allennlp.common.plugins - Plugin allennlp_models could not be loaded: No module named 'transformers.tokenization_bert'\n",
      "2022-02-25 18:36:51,665 - INFO - cached_path - cache of https://storage.googleapis.com/allennlp-public-models/basic_stanford_sentiment_treebank-2020.06.09.tar.gz is up-to-date\n",
      "2022-02-25 18:36:51,666 - INFO - allennlp.models.archival - loading archive file https://storage.googleapis.com/allennlp-public-models/basic_stanford_sentiment_treebank-2020.06.09.tar.gz from cache at /Users/anam/.allennlp/cache/a6cc14fc8a3970ecd7dd29cfdb352b0481f4b253eddd52e2b2a92e2a1ad0ca1b.933ed3c54ce1300985e2c0c124ee818dde430c718deca4e72a9a42ff857a4bdf\n",
      "2022-02-25 18:36:51,667 - INFO - allennlp.models.archival - extracting archive file /Users/anam/.allennlp/cache/a6cc14fc8a3970ecd7dd29cfdb352b0481f4b253eddd52e2b2a92e2a1ad0ca1b.933ed3c54ce1300985e2c0c124ee818dde430c718deca4e72a9a42ff857a4bdf to temp dir /var/folders/qr/8__6lqs525vbb3xk4c52jhxc0000gp/T/tmpua2mkdit\n",
      "2022-02-25 18:36:52,003 - INFO - allennlp.common.params - dataset_reader.type = sst_tokens\n",
      "2022-02-25 18:36:52,004 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-02-25 18:36:52,004 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-02-25 18:36:52,005 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-02-25 18:36:52,006 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2022-02-25 18:36:52,007 - INFO - allennlp.common.params - dataset_reader.tokenizer = None\n",
      "2022-02-25 18:36:52,008 - INFO - allennlp.common.params - dataset_reader.use_subtrees = True\n",
      "2022-02-25 18:36:52,008 - INFO - allennlp.common.params - dataset_reader.granularity = 2-class\n",
      "2022-02-25 18:36:52,009 - INFO - allennlp.common.params - validation_dataset_reader.type = sst_tokens\n",
      "2022-02-25 18:36:52,010 - INFO - allennlp.common.params - validation_dataset_reader.max_instances = None\n",
      "2022-02-25 18:36:52,010 - INFO - allennlp.common.params - validation_dataset_reader.manual_distributed_sharding = False\n",
      "2022-02-25 18:36:52,011 - INFO - allennlp.common.params - validation_dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-02-25 18:36:52,012 - INFO - allennlp.common.params - validation_dataset_reader.token_indexers = None\n",
      "2022-02-25 18:36:52,012 - INFO - allennlp.common.params - validation_dataset_reader.tokenizer = None\n",
      "2022-02-25 18:36:52,013 - INFO - allennlp.common.params - validation_dataset_reader.use_subtrees = False\n",
      "2022-02-25 18:36:52,013 - INFO - allennlp.common.params - validation_dataset_reader.granularity = 2-class\n",
      "2022-02-25 18:36:52,014 - INFO - allennlp.common.params - type = from_instances\n",
      "2022-02-25 18:36:52,015 - INFO - allennlp.data.vocabulary - Loading token dictionary from /var/folders/qr/8__6lqs525vbb3xk4c52jhxc0000gp/T/tmpua2mkdit/vocabulary.\n",
      "2022-02-25 18:36:52,032 - INFO - allennlp.common.params - model.type = basic_classifier\n",
      "2022-02-25 18:36:52,034 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2022-02-25 18:36:52,035 - INFO - allennlp.common.params - model.ddp_accelerator = None\n",
      "2022-02-25 18:36:52,036 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n",
      "2022-02-25 18:36:52,037 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = embedding\n",
      "2022-02-25 18:36:52,038 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.embedding_dim = 300\n",
      "2022-02-25 18:36:52,039 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.num_embeddings = None\n",
      "2022-02-25 18:36:52,040 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.projection_dim = None\n",
      "2022-02-25 18:36:52,041 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.weight = None\n",
      "2022-02-25 18:36:52,041 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.padding_index = None\n",
      "2022-02-25 18:36:52,042 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.trainable = False\n",
      "2022-02-25 18:36:52,042 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_norm = None\n",
      "2022-02-25 18:36:52,043 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.norm_type = 2.0\n",
      "2022-02-25 18:36:52,043 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.scale_grad_by_freq = False\n",
      "2022-02-25 18:36:52,043 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sparse = False\n",
      "2022-02-25 18:36:52,044 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.vocab_namespace = tokens\n",
      "2022-02-25 18:36:52,044 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.pretrained_file = None\n",
      "2022-02-25 18:36:52,070 - INFO - allennlp.common.params - model.seq2vec_encoder.type = lstm\n",
      "2022-02-25 18:36:52,071 - INFO - allennlp.common.params - model.seq2vec_encoder.input_size = 300\n",
      "2022-02-25 18:36:52,072 - INFO - allennlp.common.params - model.seq2vec_encoder.hidden_size = 512\n",
      "2022-02-25 18:36:52,072 - INFO - allennlp.common.params - model.seq2vec_encoder.num_layers = 2\n",
      "2022-02-25 18:36:52,073 - INFO - allennlp.common.params - model.seq2vec_encoder.bias = True\n",
      "2022-02-25 18:36:52,074 - INFO - allennlp.common.params - model.seq2vec_encoder.dropout = 0.0\n",
      "2022-02-25 18:36:52,074 - INFO - allennlp.common.params - model.seq2vec_encoder.bidirectional = False\n",
      "2022-02-25 18:36:52,090 - INFO - allennlp.common.params - model.seq2seq_encoder = None\n",
      "2022-02-25 18:36:52,090 - INFO - allennlp.common.params - model.feedforward = None\n",
      "2022-02-25 18:36:52,091 - INFO - allennlp.common.params - model.dropout = None\n",
      "2022-02-25 18:36:52,092 - INFO - allennlp.common.params - model.num_labels = None\n",
      "2022-02-25 18:36:52,092 - INFO - allennlp.common.params - model.label_namespace = labels\n",
      "2022-02-25 18:36:52,093 - INFO - allennlp.common.params - model.namespace = tokens\n",
      "2022-02-25 18:36:52,093 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7fc144545a90>\n",
      "2022-02-25 18:36:52,094 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2022-02-25 18:36:52,095 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2022-02-25 18:36:52,095 - INFO - allennlp.nn.initializers -    _classification_layer.bias\n",
      "2022-02-25 18:36:52,096 - INFO - allennlp.nn.initializers -    _classification_layer.weight\n",
      "2022-02-25 18:36:52,096 - INFO - allennlp.nn.initializers -    _seq2vec_encoder._module.bias_hh_l0\n",
      "2022-02-25 18:36:52,097 - INFO - allennlp.nn.initializers -    _seq2vec_encoder._module.bias_hh_l1\n",
      "2022-02-25 18:36:52,097 - INFO - allennlp.nn.initializers -    _seq2vec_encoder._module.bias_ih_l0\n",
      "2022-02-25 18:36:52,098 - INFO - allennlp.nn.initializers -    _seq2vec_encoder._module.bias_ih_l1\n",
      "2022-02-25 18:36:52,098 - INFO - allennlp.nn.initializers -    _seq2vec_encoder._module.weight_hh_l0\n",
      "2022-02-25 18:36:52,099 - INFO - allennlp.nn.initializers -    _seq2vec_encoder._module.weight_hh_l1\n",
      "2022-02-25 18:36:52,099 - INFO - allennlp.nn.initializers -    _seq2vec_encoder._module.weight_ih_l0\n",
      "2022-02-25 18:36:52,099 - INFO - allennlp.nn.initializers -    _seq2vec_encoder._module.weight_ih_l1\n",
      "2022-02-25 18:36:52,100 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.weight\n",
      "2022-02-25 18:36:52,117 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /var/folders/qr/8__6lqs525vbb3xk4c52jhxc0000gp/T/tmpua2mkdit\n"
     ]
    }
   ],
   "source": [
    "from allennlp.interpret.saliency_interpreters import SimpleGradient\n",
    "from allennlp.predictors import Predictor\n",
    "\n",
    "archive = (\n",
    "    \"https://storage.googleapis.com/allennlp-public-models/\"\n",
    "    \"basic_stanford_sentiment_treebank-2020.06.09.tar.gz\"\n",
    ")\n",
    "predictor = Predictor.from_path(archive)\n",
    "interpreter = SimpleGradient(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d2ee96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this 0.004374315073110228\n",
      "movie 0.01883447832886506\n",
      "is 0.040131830169589024\n",
      "10 0.33293188191427076\n",
      "/ 0.3059516655881175\n",
      "10 0.2592315336969585\n",
      ". 0.03854428921039927\n"
     ]
    }
   ],
   "source": [
    "from allennlp.data.tokenizers.spacy_tokenizer import SpacyTokenizer\n",
    "\n",
    "inputs = {\"sentence\": \"this movie is 10 / 10.\"}\n",
    "interpretation = interpreter.saliency_interpret_from_json(inputs)\n",
    "\n",
    "tokenized_sentence = SpacyTokenizer().tokenize(inputs[\"sentence\"])\n",
    "\n",
    "sentence_attribution = zip(tokenized_sentence, interpretation[\"instance_1\"][\"grad_input_1\"])\n",
    "\n",
    "for word, grad in sentence_attribution: \n",
    "    print (word, grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f7f68",
   "metadata": {},
   "source": [
    "### Option 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ef94ea",
   "metadata": {},
   "source": [
    "https://github.com/successar/instance_attributions_NLP\n",
    "\n",
    "Use allennlp to first learn a classifier and then calculate different instance attribution methods on it\n",
    "\n",
    "The scripts which calculate the different instance attributions are in this directory: https://github.com/successar/instance_attributions_NLP/tree/master/influence_info/influencers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7eabb7",
   "metadata": {},
   "source": [
    "### Option 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e4382d",
   "metadata": {},
   "source": [
    "https://guide.allennlp.org/interpret#5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e864b",
   "metadata": {},
   "source": [
    "## Combining Word and Instance Attribution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df6c4d3",
   "metadata": {},
   "source": [
    "Apply feature attribution on top of instance attribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fc76f6",
   "metadata": {},
   "source": [
    "https://github.com/successar/instance_attributions_NLP/tree/master/influence_info/influencers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1298a7",
   "metadata": {},
   "source": [
    "## Contrastive Edits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530fd7ce",
   "metadata": {},
   "source": [
    "https://github.com/allenai/mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e64f85e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
