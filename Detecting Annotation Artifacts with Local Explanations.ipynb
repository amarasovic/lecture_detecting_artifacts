{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ef54e3f",
   "metadata": {},
   "source": [
    "# Detecting Annotation Artifacts with Local Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c2999",
   "metadata": {},
   "source": [
    "An input feature is a data artifact if there exists correlation between a task label and the feature in the training data, but this correlation is not true reflection of the real world.\n",
    "\n",
    "Local explanations are explanations of individual predictions made by some model. We will go over three methods for producing local explanations: gradient-based highlighting of input, finding influential training examples, and contrastive editing---in the context of finding annotation artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed95189",
   "metadata": {},
   "source": [
    "## Task and Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32c0e43",
   "metadata": {},
   "source": [
    "We will demonstrate how to detect annotation artifacts in the context of **binary sentiment classification** of movie reviews, i.e., classifying a given movie review as positive or negative. One commonly used dataset for this task is the [IMDB dataset](http://ai.stanford.edu/~amaas/data/sentiment/). A useful library for accessing NLP datasets is [datasets by Huggingface](https://huggingface.co/docs/datasets/) ðŸ¤—. We can load the IMDB dataset using `datasets` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca8ec5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a9d89d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864bc438",
   "metadata": {},
   "source": [
    "This loads a `DatasetDict` object which you can index into to view an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca939ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e0c57f",
   "metadata": {},
   "source": [
    "You can select an example randomly like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c99c6cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'There are several things wrong with this movie- Brenda Song\\'s character being one of them. I do not believe that the girl is a lousy actor- I honestly don\\'t. I believe she is given poor lines. She is just supposed to be, \"that vain, rich girl\", and while it is funny in the TV shows she plays in, it can\\'t even get a dry laugh from me here.<br /><br />Either way, I really should have known what to expect when I sat down to watch this film.<br /><br />The movie was not that terrible...initially. Wendy\\'s reaction to Shen was completely natural. I mean, how would you feel if a man, claiming to be a reincarnated monk, chased you around commanding you to wear a medallion and insisting that you were needed to fight \"the great evil\" and save the world? Which brings me to another point. I know this movie is entirely fiction, but it is still has a founding in Chinese culture. It seems like all of the \"warriors\" in Wendy\\'s family line were women. Correct me if I\\'m wrong, but I doubt that the monks would\\'ve just been okay with that. Sure, maybe they could\\'ve worked it in somehow, but they offered no explanation whatsoever. By doing so, they just contributed to the many cheesy attempts at female empowerment made by Hollywood and the media.<br /><br />Nevermind that, however- let us continue.<br /><br />Wendy\\'s character becomes more unbearable as the film go on. Yes, she is a teenager, and it is near homecoming- I mean, who wants to fight evil during homecoming? The problem is, when \"the evil\" starts to manifest himself, Wendy does not seem as freaked out as she should be. She is extremely careless- even for someone like her. She continues not to care about her training. I will use this conversation as an example, Shen: \"If you do not win this battle, evil will take over, and everything good will be gone.\" Wendy: \"Whoa, talk about pressure. Well...let\\'s talk about something else.\" Yes, let\\'s Wendy. Let\\'s also go dancing when you should rightfully be training. Of course Shen lets her, but his character has an excuse. Better that he cooperate with her, than that he not, and she not train at all, and get them both killed.<br /><br />Oh, speaking of which. Shen also told Wendy that it was his destiny for him to die for her in battle, as he had for her great-grandmother (I am assuming that part).<br /><br />This makes Wendy\\'s actions more unforgivable.<br /><br />As the script-writer would have it, Wendy\\'s homecoming and this \"great battle\" are on exactly the same day. Do you know what Wendy does? Do you even have to guess? Yes, she does end up going to the battle, for when she tries to leave for homecoming, the monks, (who Shen had trapped in the body of her coach and teachers because she \"felt weird fighting an old man\") inform her that Shen has gone to battle alone, so she goes to save him.<br /><br />We initially see some half-decent fighting, that is actually entertaining. Until finally, the great evil comes out of Wendy\\'s rival-for-homecoming\\'s body, and creates the actual embodiment of himself out of the broken pieces of the bodies of his ancient warriors.<br /><br />Don\\'t ask.<br /><br />Anyway, Wendy gets all \"panicky.\" Then Shen goes and defends her from this guy- forgive me for forgetting his long Chinese name- and manages to get himself killed.<br /><br />Wendy catches Shen as he makes his long descent from being thrust uncomfortably high into the air.<br /><br />She screams title of said article out.<br /><br />Now...it was bad enough that Wendy became powerful far, far too fast. No, I will not let it be excused because it was her \"destiny\" and she had \"the power within\" her.<br /><br />Since when, though, did she learn healing? No, worst...since when could she resurrect people? So Shen is raised from the dead. Then, Wendy and he fight the guy.<br /><br />He loses way to easily. The worst part, is when they jump together, and kick him at the same time, and he is banished forever. Then the monks commend Wendy on her sacrifice.<br /><br />Two things, #1: Don\\'t the script writer and director know a battle needs a little more \"finesse\" to it? #2: What sacrifice? The fact that she didn\\'t go to homecoming? Because the girl did not break a sweat, or even bleed. I mean, come on now, this movie was TV PG, I wanted to see somebody get hurt.<br /><br />Ah-hem...moving on.<br /><br />I know it sounds like maybe I should have given the movie a one, based on my comments. Part of critique, you must know, though, is breaking a thing down. You don\\'t necessarily try to look for the bad, but if it\\'s there, you bring attention to it. This movie has a lot of bad, but something funny happens when you never really expect something to be all too great in the first place.<br /><br />So, I suppose it was all right. Not that me not saying it wasn\\'t all right would\\'ve stopped anybody from watching it.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].shuffle().select(range(1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd72e43",
   "metadata": {},
   "source": [
    "Where `label: 1` means that the movie review is positive, and `negative` otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed5a2e5",
   "metadata": {},
   "source": [
    "## Annotation Artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76c2e43",
   "metadata": {},
   "source": [
    "It has been reported that neural models trained for the task of binary sentiment classification solely use the numberical rating at the end of the review instead of reading and understanding the semantics of the review. We will focus on that annotation artifact in this notebook. Let's collect all test instances with numerical rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dd18cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_with_scores = []\n",
    "\n",
    "for instance in dataset[\"train\"]:\n",
    "    instance[\"text\"] = instance[\"text\"].replace('/10', ' / 10')\n",
    "    if \"/ 10\" in instance[\"text\"] or \"/10\" in instance[\"text\"]:\n",
    "        instances_with_scores.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be24af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"There are {len(instances_with_scores)} instances with a numerical rating.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5119d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"One example labeled as negative: {instances_with_scores[0]['text']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5831080",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c06beb7",
   "metadata": {},
   "source": [
    "We will analyze a [RoBERTa-large](https://arxiv.org/abs/1907.11692) classifier that is already trained for binary sentiment classfication in the IMDB dataset with the [AllenNLP](https://allenai.org/allennlp/software/allennlp-library) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cac6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors import Predictor\n",
    "from mice.src.predictors.imdb.imdb_dataset_reader import ImdbDatasetReader\n",
    "\n",
    "archive = \"mice/trained_predictors/imdb/model/model.tar.gz\"\n",
    "predictor = Predictor.from_path(archive, dataset_reader_to_load=ImdbDatasetReader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a415feb",
   "metadata": {},
   "source": [
    "## Gradient-Based Highlights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a9b435",
   "metadata": {},
   "source": [
    "Let's randomly sample one movie review with a numerical rating and get the model's prediction for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9ae2e4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold label: negative, Predicted label: negative\n",
      "Damn, I thought I'd seen some bad westerns. Can't top this one though. Hell I think I'd rather have my eyes stapled open for a Trinity Triple Feature for cryin out loud. I dont think I'll be able to watch Ben Hur again without laughing my ass off. Just really bad.  But hey, if you like stupid westerns with acknowledged stars in the thing take a peek at Shoot Out with Gregory Peck. It's just as bad, but much funnier. 1 / 10\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from mice.src.predictors.imdb.imdb_dataset_reader import clean_text\n",
    "\n",
    "random_instance = random.sample(instances_with_scores, 1)[0]\n",
    "random_instance[\"text\"] = clean_text(random_instance[\"text\"], special_chars=[\"<br />\", \"\\t\"])\n",
    "\n",
    "int_to_label = [\"negative\", \"positive\"]\n",
    "gold_label = int_to_label[random_instance[\"label\"]]\n",
    "pred_label = int_to_label[int(predictor.predict(random_instance[\"text\"])[\"label\"])]\n",
    "\n",
    "print(f\"Gold label: {gold_label}, Predicted label: {pred_label}\")\n",
    "print(random_instance[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9077f9",
   "metadata": {},
   "source": [
    "Now, get the gradient-based highlights for that instance using the [AllenNLP Interpret](https://allenai.github.io/allennlp-website/interpret) toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9d2ee96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anam/miniconda3/envs/lecture_env/lib/python3.7/site-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    }
   ],
   "source": [
    "from allennlp.data.tokenizers.spacy_tokenizer import SpacyTokenizer\n",
    "from allennlp.interpret.saliency_interpreters import SimpleGradient\n",
    "\n",
    "interpreter = SimpleGradient(predictor)\n",
    "\n",
    "interpretation = interpreter.saliency_interpret_from_json({\"sentence\": random_instance[\"text\"]})\n",
    "\n",
    "tokenized_sentence = SpacyTokenizer().tokenize(random_instance[\"text\"])\n",
    "\n",
    "sentence_attribution = zip(tokenized_sentence, interpretation[\"instance_1\"][\"grad_input_1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5890484a",
   "metadata": {},
   "source": [
    "We can rank input words based on the gradient magnitude and also highlight all words with the gradient higher than some `treshold`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "946e7d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_b384fdb2_982c_11ec_8bbd_acde48001122row0_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row0_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row0_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row2_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row2_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row2_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row7_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row7_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row7_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row9_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row9_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row9_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row10_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row10_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row10_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row11_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row11_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row11_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row12_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row12_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row12_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row13_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row13_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row13_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row14_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row14_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row14_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row16_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row16_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row16_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row19_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row19_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row19_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row20_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row20_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row20_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row21_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row21_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row21_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row22_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row22_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row22_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row25_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row25_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row25_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row27_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row27_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row27_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row28_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row28_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row28_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row30_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row30_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row30_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row34_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row34_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row34_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row35_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row35_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row35_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row36_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row36_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row36_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row38_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row38_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row38_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row39_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row39_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row39_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row41_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row41_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row41_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row42_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row42_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row42_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row43_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row43_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row43_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row44_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row44_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row44_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row47_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row47_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row47_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row49_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row49_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row49_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row50_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row50_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row50_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row54_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row54_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row54_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row57_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row57_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row57_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row59_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row59_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row59_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row61_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row61_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row61_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row62_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row62_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row62_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row63_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row63_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row63_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row64_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row64_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row64_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row65_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row65_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row65_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row66_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row66_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row66_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row67_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row67_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row67_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row68_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row68_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row68_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row69_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row69_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row69_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row73_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row73_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row73_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row74_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row74_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row74_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row76_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row76_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row76_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row78_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row78_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row78_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row79_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row79_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row79_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row80_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row80_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row80_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row81_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row81_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row81_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row82_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row82_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row82_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row83_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row83_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row83_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row84_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row84_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row84_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row85_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row85_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row85_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row86_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row86_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row86_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row87_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row87_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row87_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row90_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row90_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row90_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row91_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row91_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row91_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row94_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row94_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row94_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row95_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row95_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row95_col2,#T_b384fdb2_982c_11ec_8bbd_acde48001122row98_col0,#T_b384fdb2_982c_11ec_8bbd_acde48001122row98_col1,#T_b384fdb2_982c_11ec_8bbd_acde48001122row98_col2{\n",
       "            background-color:  #ff33aa;\n",
       "        }</style><table id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >word</th>        <th class=\"col_heading level0 col1\" >grad</th>        <th class=\"col_heading level0 col2\" >rank</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row0_col0\" class=\"data row0 col0\" >Damn</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row0_col1\" class=\"data row0 col1\" >0.010783</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row0_col2\" class=\"data row0 col2\" >30</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row1_col0\" class=\"data row1 col0\" >,</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row1_col1\" class=\"data row1 col1\" >0.003142</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row1_col2\" class=\"data row1 col2\" >80</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row2_col0\" class=\"data row2 col0\" >I</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row2_col1\" class=\"data row2 col1\" >0.013216</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row2_col2\" class=\"data row2 col2\" >22</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row3_col0\" class=\"data row3 col0\" >thought</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row3_col1\" class=\"data row3 col1\" >0.003627</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row3_col2\" class=\"data row3 col2\" >74</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row4_col0\" class=\"data row4 col0\" >I</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row4_col1\" class=\"data row4 col1\" >0.000863</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row4_col2\" class=\"data row4 col2\" >95</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row5_col0\" class=\"data row5 col0\" >'d</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row5_col1\" class=\"data row5 col1\" >0.002632</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row5_col2\" class=\"data row5 col2\" >83</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row6_col0\" class=\"data row6 col0\" >seen</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row6_col1\" class=\"data row6 col1\" >0.004745</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row6_col2\" class=\"data row6 col2\" >62</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row7_col0\" class=\"data row7 col0\" >some</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row7_col1\" class=\"data row7 col1\" >0.010181</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row7_col2\" class=\"data row7 col2\" >33</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row8_col0\" class=\"data row8 col0\" >bad</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row8_col1\" class=\"data row8 col1\" >0.003405</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row8_col2\" class=\"data row8 col2\" >78</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row9_col0\" class=\"data row9 col0\" >westerns</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row9_col1\" class=\"data row9 col1\" >0.015349</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row9_col2\" class=\"data row9 col2\" >14</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row10_col0\" class=\"data row10 col0\" >.</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row10_col1\" class=\"data row10 col1\" >0.032852</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row10_col2\" class=\"data row10 col2\" >2</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row11_col0\" class=\"data row11 col0\" >Ca</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row11_col1\" class=\"data row11 col1\" >0.019870</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row11_col2\" class=\"data row11 col2\" >10</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row12_col0\" class=\"data row12 col0\" >n't</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row12_col1\" class=\"data row12 col1\" >0.014964</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row12_col2\" class=\"data row12 col2\" >17</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row13_col0\" class=\"data row13 col0\" >top</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row13_col1\" class=\"data row13 col1\" >0.015776</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row13_col2\" class=\"data row13 col2\" >13</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row14_col0\" class=\"data row14 col0\" >this</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row14_col1\" class=\"data row14 col1\" >0.012086</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row14_col2\" class=\"data row14 col2\" >28</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row15_col0\" class=\"data row15 col0\" >one</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row15_col1\" class=\"data row15 col1\" >0.003707</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row15_col2\" class=\"data row15 col2\" >71</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row16_col0\" class=\"data row16 col0\" >though</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row16_col1\" class=\"data row16 col1\" >0.023138</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row16_col2\" class=\"data row16 col2\" >7</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row17_col0\" class=\"data row17 col0\" >.</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row17_col1\" class=\"data row17 col1\" >0.002061</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row17_col2\" class=\"data row17 col2\" >88</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row18_col0\" class=\"data row18 col0\" >Hell</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row18_col1\" class=\"data row18 col1\" >0.001426</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row18_col2\" class=\"data row18 col2\" >91</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row19_col0\" class=\"data row19 col0\" >I</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row19_col1\" class=\"data row19 col1\" >0.007075</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row19_col2\" class=\"data row19 col2\" >52</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row20_col0\" class=\"data row20 col0\" >think</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row20_col1\" class=\"data row20 col1\" >0.010050</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row20_col2\" class=\"data row20 col2\" >35</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row21_col0\" class=\"data row21 col0\" >I</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row21_col1\" class=\"data row21 col1\" >0.005009</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row21_col2\" class=\"data row21 col2\" >60</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row22_col0\" class=\"data row22 col0\" >'d</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row22_col1\" class=\"data row22 col1\" >0.006361</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row22_col2\" class=\"data row22 col2\" >55</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row23_col0\" class=\"data row23 col0\" >rather</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row23_col1\" class=\"data row23 col1\" >0.003778</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row23_col2\" class=\"data row23 col2\" >69</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row24_col0\" class=\"data row24 col0\" >have</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row24_col1\" class=\"data row24 col1\" >0.002675</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row24_col2\" class=\"data row24 col2\" >82</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row25_col0\" class=\"data row25 col0\" >my</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row25_col1\" class=\"data row25 col1\" >0.007737</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row25_col2\" class=\"data row25 col2\" >47</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row26_col0\" class=\"data row26 col0\" >eyes</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row26_col1\" class=\"data row26 col1\" >0.002181</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row26_col2\" class=\"data row26 col2\" >85</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row27_col0\" class=\"data row27 col0\" >stapled</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row27_col1\" class=\"data row27 col1\" >0.006102</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row27_col2\" class=\"data row27 col2\" >56</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row28_col0\" class=\"data row28 col0\" >open</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row28_col1\" class=\"data row28 col1\" >0.012694</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row28_col2\" class=\"data row28 col2\" >24</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row29_col0\" class=\"data row29 col0\" >for</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row29_col1\" class=\"data row29 col1\" >0.002560</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row29_col2\" class=\"data row29 col2\" >84</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row30_col0\" class=\"data row30 col0\" >a</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row30_col1\" class=\"data row30 col1\" >0.006475</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row30_col2\" class=\"data row30 col2\" >54</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row31_col0\" class=\"data row31 col0\" >Trinity</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row31_col1\" class=\"data row31 col1\" >0.003628</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row31_col2\" class=\"data row31 col2\" >73</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row32_col0\" class=\"data row32 col0\" >Triple</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row32_col1\" class=\"data row32 col1\" >0.001055</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row32_col2\" class=\"data row32 col2\" >94</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row33_col0\" class=\"data row33 col0\" >Feature</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row33_col1\" class=\"data row33 col1\" >0.003634</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row33_col2\" class=\"data row33 col2\" >72</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row34_col0\" class=\"data row34 col0\" >for</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row34_col1\" class=\"data row34 col1\" >0.012615</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row34_col2\" class=\"data row34 col2\" >25</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row35_col0\" class=\"data row35 col0\" >cryin</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row35_col1\" class=\"data row35 col1\" >0.052187</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row35_col2\" class=\"data row35 col2\" >1</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row36_col0\" class=\"data row36 col0\" >out</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row36_col1\" class=\"data row36 col1\" >0.014700</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row36_col2\" class=\"data row36 col2\" >18</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row37_col0\" class=\"data row37 col0\" >loud</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row37_col1\" class=\"data row37 col1\" >0.002148</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row37_col2\" class=\"data row37 col2\" >86</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row38_col0\" class=\"data row38 col0\" >.</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row38_col1\" class=\"data row38 col1\" >0.009458</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row38_col2\" class=\"data row38 col2\" >36</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row39_col0\" class=\"data row39 col0\" >I</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row39_col1\" class=\"data row39 col1\" >0.008637</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row39_col2\" class=\"data row39 col2\" >42</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row40_col0\" class=\"data row40 col0\" >do</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row40_col1\" class=\"data row40 col1\" >0.004007</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row40_col2\" class=\"data row40 col2\" >67</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row41_col0\" class=\"data row41 col0\" >nt</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row41_col1\" class=\"data row41 col1\" >0.007955</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row41_col2\" class=\"data row41 col2\" >46</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row42_col0\" class=\"data row42 col0\" >think</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row42_col1\" class=\"data row42 col1\" >0.008290</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row42_col2\" class=\"data row42 col2\" >43</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row43_col0\" class=\"data row43 col0\" >I</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row43_col1\" class=\"data row43 col1\" >0.005920</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row43_col2\" class=\"data row43 col2\" >57</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row44_col0\" class=\"data row44 col0\" >'ll</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row44_col1\" class=\"data row44 col1\" >0.005118</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row44_col2\" class=\"data row44 col2\" >59</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row45_col0\" class=\"data row45 col0\" >be</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row45_col1\" class=\"data row45 col1\" >0.004752</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row45_col2\" class=\"data row45 col2\" >61</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row46_col0\" class=\"data row46 col0\" >able</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row46_col1\" class=\"data row46 col1\" >0.000305</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row46_col2\" class=\"data row46 col2\" >97</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row47_col0\" class=\"data row47 col0\" >to</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row47_col1\" class=\"data row47 col1\" >0.006660</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row47_col2\" class=\"data row47 col2\" >53</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row48_col0\" class=\"data row48 col0\" >watch</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row48_col1\" class=\"data row48 col1\" >0.003601</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row48_col2\" class=\"data row48 col2\" >75</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row49_col0\" class=\"data row49 col0\" >Ben</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row49_col1\" class=\"data row49 col1\" >0.007150</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row49_col2\" class=\"data row49 col2\" >50</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row50_col0\" class=\"data row50 col0\" >Hur</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row50_col1\" class=\"data row50 col1\" >0.005119</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row50_col2\" class=\"data row50 col2\" >58</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row51_col0\" class=\"data row51 col0\" >again</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row51_col1\" class=\"data row51 col1\" >0.000021</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row51_col2\" class=\"data row51 col2\" >99</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row52_col0\" class=\"data row52 col0\" >without</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row52_col1\" class=\"data row52 col1\" >0.000299</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row52_col2\" class=\"data row52 col2\" >98</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row53_col0\" class=\"data row53 col0\" >laughing</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row53_col1\" class=\"data row53 col1\" >0.003774</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row53_col2\" class=\"data row53 col2\" >70</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row54_col0\" class=\"data row54 col0\" >my</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row54_col1\" class=\"data row54 col1\" >0.019866</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row54_col2\" class=\"data row54 col2\" >11</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row55_col0\" class=\"data row55 col0\" >ass</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row55_col1\" class=\"data row55 col1\" >0.004700</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row55_col2\" class=\"data row55 col2\" >63</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row56_col0\" class=\"data row56 col0\" >off</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row56_col1\" class=\"data row56 col1\" >0.004046</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row56_col2\" class=\"data row56 col2\" >66</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row57_col0\" class=\"data row57 col0\" >.</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row57_col1\" class=\"data row57 col1\" >0.011844</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row57_col2\" class=\"data row57 col2\" >29</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row58_col0\" class=\"data row58 col0\" >Just</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row58_col1\" class=\"data row58 col1\" >0.001229</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row58_col2\" class=\"data row58 col2\" >93</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row59\" class=\"row_heading level0 row59\" >59</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row59_col0\" class=\"data row59 col0\" >really</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row59_col1\" class=\"data row59 col1\" >0.008015</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row59_col2\" class=\"data row59 col2\" >45</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row60\" class=\"row_heading level0 row60\" >60</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row60_col0\" class=\"data row60 col0\" >bad</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row60_col1\" class=\"data row60 col1\" >0.002113</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row60_col2\" class=\"data row60 col2\" >87</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row61\" class=\"row_heading level0 row61\" >61</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row61_col0\" class=\"data row61 col0\" >.</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row61_col1\" class=\"data row61 col1\" >0.009049</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row61_col2\" class=\"data row61 col2\" >39</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row62\" class=\"row_heading level0 row62\" >62</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row62_col0\" class=\"data row62 col0\" >But</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row62_col1\" class=\"data row62 col1\" >0.010171</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row62_col2\" class=\"data row62 col2\" >34</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row63\" class=\"row_heading level0 row63\" >63</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row63_col0\" class=\"data row63 col0\" >hey</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row63_col1\" class=\"data row63 col1\" >0.024492</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row63_col2\" class=\"data row63 col2\" >5</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row64\" class=\"row_heading level0 row64\" >64</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row64_col0\" class=\"data row64 col0\" >,</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row64_col1\" class=\"data row64 col1\" >0.014270</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row64_col2\" class=\"data row64 col2\" >19</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row65\" class=\"row_heading level0 row65\" >65</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row65_col0\" class=\"data row65 col0\" >if</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row65_col1\" class=\"data row65 col1\" >0.025474</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row65_col2\" class=\"data row65 col2\" >4</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row66\" class=\"row_heading level0 row66\" >66</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row66_col0\" class=\"data row66 col0\" >you</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row66_col1\" class=\"data row66 col1\" >0.008171</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row66_col2\" class=\"data row66 col2\" >44</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row67\" class=\"row_heading level0 row67\" >67</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row67_col0\" class=\"data row67 col0\" >like</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row67_col1\" class=\"data row67 col1\" >0.025893</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row67_col2\" class=\"data row67 col2\" >3</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row68\" class=\"row_heading level0 row68\" >68</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row68_col0\" class=\"data row68 col0\" >stupid</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row68_col1\" class=\"data row68 col1\" >0.022971</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row68_col2\" class=\"data row68 col2\" >8</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row69\" class=\"row_heading level0 row69\" >69</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row69_col0\" class=\"data row69 col0\" >westerns</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row69_col1\" class=\"data row69 col1\" >0.020459</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row69_col2\" class=\"data row69 col2\" >9</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row70\" class=\"row_heading level0 row70\" >70</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row70_col0\" class=\"data row70 col0\" >with</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row70_col1\" class=\"data row70 col1\" >0.004092</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row70_col2\" class=\"data row70 col2\" >65</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row71\" class=\"row_heading level0 row71\" >71</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row71_col0\" class=\"data row71 col0\" >acknowledged</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row71_col1\" class=\"data row71 col1\" >0.001375</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row71_col2\" class=\"data row71 col2\" >92</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row72\" class=\"row_heading level0 row72\" >72</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row72_col0\" class=\"data row72 col0\" >stars</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row72_col1\" class=\"data row72 col1\" >0.003329</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row72_col2\" class=\"data row72 col2\" >79</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row73\" class=\"row_heading level0 row73\" >73</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row73_col0\" class=\"data row73 col0\" >in</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row73_col1\" class=\"data row73 col1\" >0.008651</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row73_col2\" class=\"data row73 col2\" >41</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row74\" class=\"row_heading level0 row74\" >74</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row74_col0\" class=\"data row74 col0\" >the</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row74_col1\" class=\"data row74 col1\" >0.007406</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row74_col2\" class=\"data row74 col2\" >48</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row75\" class=\"row_heading level0 row75\" >75</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row75_col0\" class=\"data row75 col0\" >thing</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row75_col1\" class=\"data row75 col1\" >0.000668</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row75_col2\" class=\"data row75 col2\" >96</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row76\" class=\"row_heading level0 row76\" >76</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row76_col0\" class=\"data row76 col0\" >take</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row76_col1\" class=\"data row76 col1\" >0.012573</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row76_col2\" class=\"data row76 col2\" >26</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row77\" class=\"row_heading level0 row77\" >77</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row77_col0\" class=\"data row77 col0\" >a</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row77_col1\" class=\"data row77 col1\" >0.003978</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row77_col2\" class=\"data row77 col2\" >68</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row78\" class=\"row_heading level0 row78\" >78</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row78_col0\" class=\"data row78 col0\" >peek</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row78_col1\" class=\"data row78 col1\" >0.009209</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row78_col2\" class=\"data row78 col2\" >38</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row79\" class=\"row_heading level0 row79\" >79</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row79_col0\" class=\"data row79 col0\" >at</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row79_col1\" class=\"data row79 col1\" >0.013887</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row79_col2\" class=\"data row79 col2\" >20</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row80\" class=\"row_heading level0 row80\" >80</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row80_col0\" class=\"data row80 col0\" >Shoot</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row80_col1\" class=\"data row80 col1\" >0.010457</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row80_col2\" class=\"data row80 col2\" >32</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row81\" class=\"row_heading level0 row81\" >81</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row81_col0\" class=\"data row81 col0\" >Out</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row81_col1\" class=\"data row81 col1\" >0.012900</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row81_col2\" class=\"data row81 col2\" >23</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row82\" class=\"row_heading level0 row82\" >82</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row82_col0\" class=\"data row82 col0\" >with</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row82_col1\" class=\"data row82 col1\" >0.007327</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row82_col2\" class=\"data row82 col2\" >49</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row83\" class=\"row_heading level0 row83\" >83</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row83_col0\" class=\"data row83 col0\" >Gregory</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row83_col1\" class=\"data row83 col1\" >0.012362</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row83_col2\" class=\"data row83 col2\" >27</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row84\" class=\"row_heading level0 row84\" >84</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row84_col0\" class=\"data row84 col0\" >Peck</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row84_col1\" class=\"data row84 col1\" >0.008811</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row84_col2\" class=\"data row84 col2\" >40</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row85\" class=\"row_heading level0 row85\" >85</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row85_col0\" class=\"data row85 col0\" >.</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row85_col1\" class=\"data row85 col1\" >0.015184</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row85_col2\" class=\"data row85 col2\" >15</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row86\" class=\"row_heading level0 row86\" >86</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row86_col0\" class=\"data row86 col0\" >It</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row86_col1\" class=\"data row86 col1\" >0.009261</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row86_col2\" class=\"data row86 col2\" >37</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row87\" class=\"row_heading level0 row87\" >87</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row87_col0\" class=\"data row87 col0\" >'s</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row87_col1\" class=\"data row87 col1\" >0.013760</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row87_col2\" class=\"data row87 col2\" >21</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row88\" class=\"row_heading level0 row88\" >88</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row88_col0\" class=\"data row88 col0\" >just</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row88_col1\" class=\"data row88 col1\" >0.003526</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row88_col2\" class=\"data row88 col2\" >77</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row89\" class=\"row_heading level0 row89\" >89</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row89_col0\" class=\"data row89 col0\" >as</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row89_col1\" class=\"data row89 col1\" >0.001466</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row89_col2\" class=\"data row89 col2\" >90</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row90\" class=\"row_heading level0 row90\" >90</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row90_col0\" class=\"data row90 col0\" >bad</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row90_col1\" class=\"data row90 col1\" >0.023472</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row90_col2\" class=\"data row90 col2\" >6</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row91\" class=\"row_heading level0 row91\" >91</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row91_col0\" class=\"data row91 col0\" >,</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row91_col1\" class=\"data row91 col1\" >0.015112</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row91_col2\" class=\"data row91 col2\" >16</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row92\" class=\"row_heading level0 row92\" >92</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row92_col0\" class=\"data row92 col0\" >but</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row92_col1\" class=\"data row92 col1\" >0.003104</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row92_col2\" class=\"data row92 col2\" >81</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row93\" class=\"row_heading level0 row93\" >93</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row93_col0\" class=\"data row93 col0\" >much</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row93_col1\" class=\"data row93 col1\" >0.004167</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row93_col2\" class=\"data row93 col2\" >64</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row94\" class=\"row_heading level0 row94\" >94</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row94_col0\" class=\"data row94 col0\" >funnier</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row94_col1\" class=\"data row94 col1\" >0.007134</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row94_col2\" class=\"data row94 col2\" >51</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row95\" class=\"row_heading level0 row95\" >95</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row95_col0\" class=\"data row95 col0\" >.</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row95_col1\" class=\"data row95 col1\" >0.010562</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row95_col2\" class=\"data row95 col2\" >31</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row96\" class=\"row_heading level0 row96\" >96</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row96_col0\" class=\"data row96 col0\" >1</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row96_col1\" class=\"data row96 col1\" >0.001852</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row96_col2\" class=\"data row96 col2\" >89</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row97\" class=\"row_heading level0 row97\" >97</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row97_col0\" class=\"data row97 col0\" >/</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row97_col1\" class=\"data row97 col1\" >0.003535</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row97_col2\" class=\"data row97 col2\" >76</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122level0_row98\" class=\"row_heading level0 row98\" >98</th>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row98_col0\" class=\"data row98 col0\" >10</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row98_col1\" class=\"data row98 col1\" >0.016220</td>\n",
       "                        <td id=\"T_b384fdb2_982c_11ec_8bbd_acde48001122row98_col2\" class=\"data row98 col2\" >12</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9d9d74cc50>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "threshold = 0.005\n",
    "cols = [\"word\", \"grad\"]\n",
    "df = pd.DataFrame(sentence_attribution, columns=cols)\n",
    "df['rank'] = df[\"grad\"].rank(ascending=False).astype(int)\n",
    "\n",
    "df.style.apply(lambda x: [\"background-color: #ff33aa\" if x.iloc[1] > threshold \n",
    "                          else \"\" for i, v in enumerate(x)], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51077f87",
   "metadata": {},
   "source": [
    "Since the input is long, it might be useful to focus on top-k words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "616e9171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>grad</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>cryin</td>\n",
       "      <td>0.052187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>.</td>\n",
       "      <td>0.032852</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>like</td>\n",
       "      <td>0.025893</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>if</td>\n",
       "      <td>0.025474</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>hey</td>\n",
       "      <td>0.024492</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>bad</td>\n",
       "      <td>0.023472</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>though</td>\n",
       "      <td>0.023138</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>stupid</td>\n",
       "      <td>0.022971</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>westerns</td>\n",
       "      <td>0.020459</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ca</td>\n",
       "      <td>0.019870</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>my</td>\n",
       "      <td>0.019866</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>10</td>\n",
       "      <td>0.016220</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>top</td>\n",
       "      <td>0.015776</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>westerns</td>\n",
       "      <td>0.015349</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>.</td>\n",
       "      <td>0.015184</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>,</td>\n",
       "      <td>0.015112</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>n't</td>\n",
       "      <td>0.014964</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>out</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>,</td>\n",
       "      <td>0.014270</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>at</td>\n",
       "      <td>0.013887</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word      grad  rank\n",
       "35     cryin  0.052187     1\n",
       "10         .  0.032852     2\n",
       "67      like  0.025893     3\n",
       "65        if  0.025474     4\n",
       "63       hey  0.024492     5\n",
       "90       bad  0.023472     6\n",
       "16    though  0.023138     7\n",
       "68    stupid  0.022971     8\n",
       "69  westerns  0.020459     9\n",
       "11        Ca  0.019870    10\n",
       "54        my  0.019866    11\n",
       "98        10  0.016220    12\n",
       "13       top  0.015776    13\n",
       "9   westerns  0.015349    14\n",
       "85         .  0.015184    15\n",
       "91         ,  0.015112    16\n",
       "12       n't  0.014964    17\n",
       "36       out  0.014700    18\n",
       "64         ,  0.014270    19\n",
       "79        at  0.013887    20"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=20\n",
    "df.sort_values(by=['grad'], ascending=False).head(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fb2472",
   "metadata": {},
   "source": [
    "Let's see which words are highlighted more than expected given their frequency in the original IMDB dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33bc321",
   "metadata": {},
   "source": [
    "We'll first calculate the number of times each word in the training dataset occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a708ef07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25000/25000 [03:08<00:00, 132.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "train_dataset = dataset[\"train\"] #.shuffle().select(range(1000))\n",
    "tokens = []\n",
    "for instance in tqdm(train_dataset): \n",
    "    tokenized_sentence = SpacyTokenizer().tokenize(instance[\"text\"])\n",
    "    tokens.extend([t.text for t in tokenized_sentence])\n",
    "\n",
    "types_freq = {k: v for k,v in Counter(tokens).items() if v>=10}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292bc067",
   "metadata": {},
   "source": [
    "Then, for all instances with the numerical ratings we want to record top-k (k=20) words. This will be slow very slow, so we will do this only for 100 such instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3645989a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [14:16<00:00,  8.56s/it]\n"
     ]
    }
   ],
   "source": [
    "k=20\n",
    "sample_size=100\n",
    "top_tokens = []\n",
    "for instance in tqdm(instances_with_scores[:sample_size]):\n",
    "    instance[\"text\"] = clean_text(instance[\"text\"], special_chars=[\"<br />\", \"\\t\"])\n",
    "    interpretation = interpreter.saliency_interpret_from_json({\"sentence\": instance[\"text\"]})\n",
    "    tokenized_sentence = SpacyTokenizer().tokenize(instance[\"text\"])\n",
    "    sentence_attribution = zip(tokenized_sentence, interpretation[\"instance_1\"][\"grad_input_1\"])\n",
    "    instance_top_tokens = [w[0].text for w in sorted(list(sentence_attribution), key = lambda x: x[1], reverse=True)]\n",
    "    top_tokens.extend(instance_top_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68558292",
   "metadata": {},
   "source": [
    "We normalized the occurance of each token `t` recorded with `Counter(top_tokens)` (how many times this token is selected sa top-k token in the sample evaluation dataset) by its original occurance in the training dataset recorded with `types_freq[t]`, and list top-10 tokens with respect to the normalized occurance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "06dc43a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tanya', 0.47619047619047616),\n",
       " ('bail', 0.4),\n",
       " ('Jox', 0.2777777777777778),\n",
       " ('Spaghetti', 0.26666666666666666),\n",
       " ('Kiki', 0.24),\n",
       " ('KGB', 0.23529411764705882),\n",
       " ('Sleepwalkers', 0.23529411764705882),\n",
       " ('Arnie', 0.23255813953488372),\n",
       " ('Zuniga', 0.2222222222222222),\n",
       " ('Chronicles', 0.21739130434782608)]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tokens_normalized = {t: v/types_freq[t] for t,v in top_tokens_freq.items() if t in types_freq}\n",
    "Counter(top_tokens_normalized).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d078a80a",
   "metadata": {},
   "source": [
    "Based on this list, highlighting with the gradient magnitude didn't identify numerical ratings as tokens that are highlighted more than expected. We could try the integrated gradient method that is more powerful (and slower). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5ac9d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.interpret.saliency_interpreters import IntegratedGradient\n",
    "\n",
    "interpreter = IntegratedGradient(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e1fa7194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–ˆâ–‰                                                                                            | 2/100 [03:26<2:48:22, 103.09s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qr/8__6lqs525vbb3xk4c52jhxc0000gp/T/ipykernel_13913/462159958.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances_with_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecial_chars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<br />\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0minterpretation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaliency_interpret_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"sentence\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtokenized_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpacyTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msentence_attribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpretation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"instance_1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"grad_input_1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lecture_env/lib/python3.7/site-packages/allennlp/interpret/saliency_interpreters/integrated_gradient.py\u001b[0m in \u001b[0;36msaliency_interpret_from_json\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_instances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# Run integrated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_integrate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# Normalize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lecture_env/lib/python3.7/site-packages/allennlp/interpret/saliency_interpreters/integrated_gradient.py\u001b[0m in \u001b[0;36m_integrate_gradients\u001b[0;34m(self, instance)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lecture_env/lib/python3.7/site-packages/allennlp/predictors/predictor.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, instances)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lecture_env/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lecture_env/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lecture_env/lib/python3.7/site-packages/allennlp/predictors/predictor.py\u001b[0m in \u001b[0;36mhook_layers\u001b[0;34m(module, grad_in, grad_out)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \"\"\"\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mhook_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_token_offsets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k=20\n",
    "sample_size=100\n",
    "top_tokens = []\n",
    "for instance in tqdm(instances_with_scores[:sample_size]):\n",
    "    instance[\"text\"] = clean_text(instance[\"text\"], special_chars=[\"<br />\", \"\\t\"])\n",
    "    interpretation = interpreter.saliency_interpret_from_json({\"sentence\": instance[\"text\"]})\n",
    "    tokenized_sentence = SpacyTokenizer().tokenize(instance[\"text\"])\n",
    "    sentence_attribution = zip(tokenized_sentence, interpretation[\"instance_1\"][\"grad_input_1\"])\n",
    "    instance_top_tokens = [w[0].text for w in sorted(list(sentence_attribution), key = lambda x: x[1], reverse=True)]\n",
    "    top_tokens.extend(instance_top_tokens)\n",
    "\n",
    "top_tokens_normalized = {t: v/types_freq[t] for t,v in top_tokens_freq.items() if t in types_freq}\n",
    "Counter(top_tokens_normalized).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53be1e53",
   "metadata": {},
   "source": [
    "## Influential Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de5fc9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 18:16:03,825 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2022-02-27 18:16:03,829 - INFO - allennlp.models.archival - loading archive file mice/trained_predictors/imdb/model/model.tar.gz\n",
      "2022-02-27 18:16:03,830 - INFO - allennlp.models.archival - extracting archive file mice/trained_predictors/imdb/model/model.tar.gz to temp dir /var/folders/qr/8__6lqs525vbb3xk4c52jhxc0000gp/T/tmp6prr7m82\n",
      "2022-02-27 18:16:13,963 - INFO - allennlp.common.params - dataset_reader.type = imdb\n",
      "2022-02-27 18:16:13,964 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-02-27 18:16:13,965 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-02-27 18:16:13,965 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-02-27 18:16:13,966 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer\n",
      "2022-02-27 18:16:13,967 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0\n",
      "2022-02-27 18:16:13,967 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-large\n",
      "2022-02-27 18:16:13,968 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags\n",
      "2022-02-27 18:16:13,968 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512\n",
      "2022-02-27 18:16:13,968 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None\n",
      "2022-02-27 18:16:13,972 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer\n",
      "2022-02-27 18:16:13,973 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-large\n",
      "2022-02-27 18:16:13,973 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True\n",
      "2022-02-27 18:16:13,974 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = 512\n",
      "2022-02-27 18:16:13,975 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None\n",
      "2022-02-27 18:16:13,976 - INFO - allennlp.common.params - dataset_reader.type = imdb\n",
      "2022-02-27 18:16:13,977 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-02-27 18:16:13,977 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-02-27 18:16:13,978 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-02-27 18:16:13,979 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer\n",
      "2022-02-27 18:16:13,980 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0\n",
      "2022-02-27 18:16:13,980 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = roberta-large\n",
      "2022-02-27 18:16:13,980 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags\n",
      "2022-02-27 18:16:13,981 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = 512\n",
      "2022-02-27 18:16:13,981 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None\n",
      "2022-02-27 18:16:13,983 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer\n",
      "2022-02-27 18:16:13,984 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = roberta-large\n",
      "2022-02-27 18:16:13,984 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True\n",
      "2022-02-27 18:16:13,985 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = 512\n",
      "2022-02-27 18:16:13,986 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None\n",
      "2022-02-27 18:16:13,987 - INFO - allennlp.common.params - type = from_instances\n",
      "2022-02-27 18:16:13,988 - INFO - allennlp.data.vocabulary - Loading token dictionary from /var/folders/qr/8__6lqs525vbb3xk4c52jhxc0000gp/T/tmp6prr7m82/vocabulary.\n",
      "2022-02-27 18:16:13,989 - INFO - allennlp.common.params - model.type = basic_classifier\n",
      "2022-02-27 18:16:13,990 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2022-02-27 18:16:13,991 - INFO - allennlp.common.params - model.ddp_accelerator = None\n",
      "2022-02-27 18:16:13,991 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n",
      "2022-02-27 18:16:13,992 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer\n",
      "2022-02-27 18:16:13,993 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = roberta-large\n",
      "2022-02-27 18:16:13,994 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = 512\n",
      "2022-02-27 18:16:13,994 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_module = None\n",
      "2022-02-27 18:16:13,995 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True\n",
      "2022-02-27 18:16:13,995 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.eval_mode = False\n",
      "2022-02-27 18:16:13,995 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True\n",
      "2022-02-27 18:16:13,996 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None\n",
      "2022-02-27 18:16:13,997 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None\n",
      "2022-02-27 18:16:13,998 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.reinit_modules = None\n",
      "2022-02-27 18:16:13,998 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.load_weights = True\n",
      "2022-02-27 18:16:13,999 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None\n",
      "2022-02-27 18:16:14,000 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None\n",
      "2022-02-27 18:16:14,000 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None\n",
      "2022-02-27 18:16:14,277 - INFO - allennlp.common.params - model.seq2vec_encoder.type = bert_pooler\n",
      "2022-02-27 18:16:14,278 - INFO - allennlp.common.params - model.seq2vec_encoder.pretrained_model = roberta-large\n",
      "2022-02-27 18:16:14,279 - INFO - allennlp.common.params - model.seq2vec_encoder.override_weights_file = None\n",
      "2022-02-27 18:16:14,280 - INFO - allennlp.common.params - model.seq2vec_encoder.override_weights_strip_prefix = None\n",
      "2022-02-27 18:16:14,281 - INFO - allennlp.common.params - model.seq2vec_encoder.load_weights = True\n",
      "2022-02-27 18:16:14,282 - INFO - allennlp.common.params - model.seq2vec_encoder.requires_grad = True\n",
      "2022-02-27 18:16:14,282 - INFO - allennlp.common.params - model.seq2vec_encoder.dropout = 0.1\n",
      "2022-02-27 18:16:14,283 - INFO - allennlp.common.params - model.seq2vec_encoder.transformer_kwargs = None\n",
      "2022-02-27 18:16:14,285 - INFO - allennlp.common.params - model.seq2seq_encoder = None\n",
      "2022-02-27 18:16:14,286 - INFO - allennlp.common.params - model.feedforward = None\n",
      "2022-02-27 18:16:14,286 - INFO - allennlp.common.params - model.dropout = None\n",
      "2022-02-27 18:16:14,287 - INFO - allennlp.common.params - model.num_labels = None\n",
      "2022-02-27 18:16:14,287 - INFO - allennlp.common.params - model.label_namespace = labels\n",
      "2022-02-27 18:16:14,288 - INFO - allennlp.common.params - model.namespace = tags\n",
      "2022-02-27 18:16:14,289 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7fcf4111e8d0>\n",
      "2022-02-27 18:16:14,291 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2022-02-27 18:16:14,293 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2022-02-27 18:16:14,295 - INFO - allennlp.nn.initializers -    _classification_layer.bias\n",
      "2022-02-27 18:16:14,295 - INFO - allennlp.nn.initializers -    _classification_layer.weight\n",
      "2022-02-27 18:16:14,296 - INFO - allennlp.nn.initializers -    _seq2vec_encoder.pooler.dense.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 18:16:14,296 - INFO - allennlp.nn.initializers -    _seq2vec_encoder.pooler.dense.weight\n",
      "2022-02-27 18:16:14,297 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias\n",
      "2022-02-27 18:16:14,298 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight\n",
      "2022-02-27 18:16:14,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight\n",
      "2022-02-27 18:16:14,299 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2022-02-27 18:16:14,301 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight\n",
      "2022-02-27 18:16:14,304 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,306 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,308 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,310 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,312 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2022-02-27 18:16:14,312 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2022-02-27 18:16:14,314 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2022-02-27 18:16:14,315 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2022-02-27 18:16:14,315 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2022-02-27 18:16:14,316 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2022-02-27 18:16:14,318 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,318 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,319 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,320 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,321 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2022-02-27 18:16:14,322 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2022-02-27 18:16:14,323 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,324 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,325 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,326 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,326 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2022-02-27 18:16:14,327 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2022-02-27 18:16:14,328 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2022-02-27 18:16:14,328 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2022-02-27 18:16:14,329 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2022-02-27 18:16:14,329 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2022-02-27 18:16:14,331 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,332 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,333 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,333 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,334 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2022-02-27 18:16:14,335 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2022-02-27 18:16:14,335 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,336 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,337 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,338 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,339 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2022-02-27 18:16:14,340 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2022-02-27 18:16:14,340 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2022-02-27 18:16:14,341 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2022-02-27 18:16:14,341 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2022-02-27 18:16:14,342 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2022-02-27 18:16:14,342 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,343 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.intermediate.dense.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 18:16:14,344 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,345 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,346 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2022-02-27 18:16:14,347 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2022-02-27 18:16:14,347 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,348 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,349 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,349 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,350 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2022-02-27 18:16:14,351 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2022-02-27 18:16:14,351 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2022-02-27 18:16:14,352 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2022-02-27 18:16:14,353 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2022-02-27 18:16:14,353 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2022-02-27 18:16:14,354 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,355 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,356 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,357 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,357 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2022-02-27 18:16:14,358 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2022-02-27 18:16:14,359 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,360 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,360 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,361 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,362 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.key.bias\n",
      "2022-02-27 18:16:14,362 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.key.weight\n",
      "2022-02-27 18:16:14,363 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.query.bias\n",
      "2022-02-27 18:16:14,363 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.query.weight\n",
      "2022-02-27 18:16:14,364 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.value.bias\n",
      "2022-02-27 18:16:14,364 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.attention.self.value.weight\n",
      "2022-02-27 18:16:14,365 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,366 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,366 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,367 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,367 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.dense.bias\n",
      "2022-02-27 18:16:14,368 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.12.output.dense.weight\n",
      "2022-02-27 18:16:14,368 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,369 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,370 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,370 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,370 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.key.bias\n",
      "2022-02-27 18:16:14,371 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.key.weight\n",
      "2022-02-27 18:16:14,372 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.query.bias\n",
      "2022-02-27 18:16:14,372 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.query.weight\n",
      "2022-02-27 18:16:14,373 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.value.bias\n",
      "2022-02-27 18:16:14,374 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.attention.self.value.weight\n",
      "2022-02-27 18:16:14,375 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,375 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,376 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,376 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.LayerNorm.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 18:16:14,377 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.dense.bias\n",
      "2022-02-27 18:16:14,377 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.13.output.dense.weight\n",
      "2022-02-27 18:16:14,378 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,379 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,379 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,379 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,380 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.key.bias\n",
      "2022-02-27 18:16:14,381 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.key.weight\n",
      "2022-02-27 18:16:14,381 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.query.bias\n",
      "2022-02-27 18:16:14,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.query.weight\n",
      "2022-02-27 18:16:14,382 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.value.bias\n",
      "2022-02-27 18:16:14,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.attention.self.value.weight\n",
      "2022-02-27 18:16:14,383 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,384 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,385 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.dense.bias\n",
      "2022-02-27 18:16:14,386 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.14.output.dense.weight\n",
      "2022-02-27 18:16:14,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,387 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,388 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,389 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.key.bias\n",
      "2022-02-27 18:16:14,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.key.weight\n",
      "2022-02-27 18:16:14,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.query.bias\n",
      "2022-02-27 18:16:14,390 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.query.weight\n",
      "2022-02-27 18:16:14,391 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.value.bias\n",
      "2022-02-27 18:16:14,392 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.attention.self.value.weight\n",
      "2022-02-27 18:16:14,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,393 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,394 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,394 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,395 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.dense.bias\n",
      "2022-02-27 18:16:14,396 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.15.output.dense.weight\n",
      "2022-02-27 18:16:14,396 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,397 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,397 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,397 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,398 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.key.bias\n",
      "2022-02-27 18:16:14,398 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.key.weight\n",
      "2022-02-27 18:16:14,399 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.query.bias\n",
      "2022-02-27 18:16:14,399 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.query.weight\n",
      "2022-02-27 18:16:14,400 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.value.bias\n",
      "2022-02-27 18:16:14,400 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.attention.self.value.weight\n",
      "2022-02-27 18:16:14,401 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,403 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,403 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,403 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,404 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.dense.bias\n",
      "2022-02-27 18:16:14,404 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.16.output.dense.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 18:16:14,405 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,406 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,406 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,407 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.key.bias\n",
      "2022-02-27 18:16:14,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.key.weight\n",
      "2022-02-27 18:16:14,408 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.query.bias\n",
      "2022-02-27 18:16:14,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.query.weight\n",
      "2022-02-27 18:16:14,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.value.bias\n",
      "2022-02-27 18:16:14,409 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.attention.self.value.weight\n",
      "2022-02-27 18:16:14,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,410 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,411 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.dense.bias\n",
      "2022-02-27 18:16:14,412 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.17.output.dense.weight\n",
      "2022-02-27 18:16:14,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,413 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,414 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.key.bias\n",
      "2022-02-27 18:16:14,415 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.key.weight\n",
      "2022-02-27 18:16:14,418 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.query.bias\n",
      "2022-02-27 18:16:14,418 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.query.weight\n",
      "2022-02-27 18:16:14,419 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.value.bias\n",
      "2022-02-27 18:16:14,419 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.attention.self.value.weight\n",
      "2022-02-27 18:16:14,419 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,420 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,420 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,421 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,421 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.dense.bias\n",
      "2022-02-27 18:16:14,421 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.18.output.dense.weight\n",
      "2022-02-27 18:16:14,422 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,422 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,423 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,423 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,423 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.key.bias\n",
      "2022-02-27 18:16:14,424 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.key.weight\n",
      "2022-02-27 18:16:14,424 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.query.bias\n",
      "2022-02-27 18:16:14,425 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.query.weight\n",
      "2022-02-27 18:16:14,425 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.value.bias\n",
      "2022-02-27 18:16:14,426 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.attention.self.value.weight\n",
      "2022-02-27 18:16:14,426 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,428 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,429 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,430 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,430 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.dense.bias\n",
      "2022-02-27 18:16:14,431 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.19.output.dense.weight\n",
      "2022-02-27 18:16:14,431 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,432 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 18:16:14,432 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,433 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,433 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2022-02-27 18:16:14,435 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2022-02-27 18:16:14,435 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2022-02-27 18:16:14,436 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2022-02-27 18:16:14,436 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2022-02-27 18:16:14,437 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2022-02-27 18:16:14,437 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,438 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,438 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,439 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,440 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2022-02-27 18:16:14,441 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2022-02-27 18:16:14,442 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,442 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,443 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,443 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,444 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.key.bias\n",
      "2022-02-27 18:16:14,444 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.key.weight\n",
      "2022-02-27 18:16:14,446 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.query.bias\n",
      "2022-02-27 18:16:14,447 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.query.weight\n",
      "2022-02-27 18:16:14,447 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.value.bias\n",
      "2022-02-27 18:16:14,448 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.attention.self.value.weight\n",
      "2022-02-27 18:16:14,448 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,449 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,449 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,450 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,450 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.dense.bias\n",
      "2022-02-27 18:16:14,450 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.20.output.dense.weight\n",
      "2022-02-27 18:16:14,451 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,451 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,452 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,453 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.key.bias\n",
      "2022-02-27 18:16:14,454 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.key.weight\n",
      "2022-02-27 18:16:14,455 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.query.bias\n",
      "2022-02-27 18:16:14,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.query.weight\n",
      "2022-02-27 18:16:14,456 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.value.bias\n",
      "2022-02-27 18:16:14,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.attention.self.value.weight\n",
      "2022-02-27 18:16:14,457 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,458 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.dense.bias\n",
      "2022-02-27 18:16:14,459 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.21.output.dense.weight\n",
      "2022-02-27 18:16:14,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,460 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,461 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.output.dense.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 18:16:14,461 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.key.bias\n",
      "2022-02-27 18:16:14,462 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.key.weight\n",
      "2022-02-27 18:16:14,462 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.query.bias\n",
      "2022-02-27 18:16:14,463 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.query.weight\n",
      "2022-02-27 18:16:14,463 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.value.bias\n",
      "2022-02-27 18:16:14,463 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.attention.self.value.weight\n",
      "2022-02-27 18:16:14,464 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,464 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,465 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,465 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,466 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.dense.bias\n",
      "2022-02-27 18:16:14,466 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.22.output.dense.weight\n",
      "2022-02-27 18:16:14,470 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,471 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,472 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,472 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,474 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.key.bias\n",
      "2022-02-27 18:16:14,475 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.key.weight\n",
      "2022-02-27 18:16:14,475 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.query.bias\n",
      "2022-02-27 18:16:14,476 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.query.weight\n",
      "2022-02-27 18:16:14,477 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.value.bias\n",
      "2022-02-27 18:16:14,477 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.attention.self.value.weight\n",
      "2022-02-27 18:16:14,478 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,478 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,479 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,479 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,480 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.dense.bias\n",
      "2022-02-27 18:16:14,481 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.23.output.dense.weight\n",
      "2022-02-27 18:16:14,482 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,482 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,483 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,483 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,484 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2022-02-27 18:16:14,485 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2022-02-27 18:16:14,485 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2022-02-27 18:16:14,486 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2022-02-27 18:16:14,488 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2022-02-27 18:16:14,488 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2022-02-27 18:16:14,489 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,490 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,490 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,491 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,491 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2022-02-27 18:16:14,492 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2022-02-27 18:16:14,493 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,493 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,494 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,494 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,495 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2022-02-27 18:16:14,496 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.key.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 18:16:14,498 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2022-02-27 18:16:14,498 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2022-02-27 18:16:14,499 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2022-02-27 18:16:14,500 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2022-02-27 18:16:14,501 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,503 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,504 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,505 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,505 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2022-02-27 18:16:14,506 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2022-02-27 18:16:14,507 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,508 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,509 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,509 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,510 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2022-02-27 18:16:14,510 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2022-02-27 18:16:14,511 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2022-02-27 18:16:14,512 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2022-02-27 18:16:14,512 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2022-02-27 18:16:14,513 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2022-02-27 18:16:14,513 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,514 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,514 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,515 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,515 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2022-02-27 18:16:14,515 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2022-02-27 18:16:14,516 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,516 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,517 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,517 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,518 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2022-02-27 18:16:14,518 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2022-02-27 18:16:14,518 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2022-02-27 18:16:14,519 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2022-02-27 18:16:14,519 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2022-02-27 18:16:14,520 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2022-02-27 18:16:14,520 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,520 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,521 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,521 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,524 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2022-02-27 18:16:14,524 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2022-02-27 18:16:14,524 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,525 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,525 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,526 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,526 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2022-02-27 18:16:14,527 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2022-02-27 18:16:14,527 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2022-02-27 18:16:14,527 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.query.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-27 18:16:14,528 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2022-02-27 18:16:14,528 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2022-02-27 18:16:14,529 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,529 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,529 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,530 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,530 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2022-02-27 18:16:14,530 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2022-02-27 18:16:14,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,531 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,532 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2022-02-27 18:16:14,533 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2022-02-27 18:16:14,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2022-02-27 18:16:14,535 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2022-02-27 18:16:14,536 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2022-02-27 18:16:14,536 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2022-02-27 18:16:14,537 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,537 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,539 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,539 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,540 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2022-02-27 18:16:14,540 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2022-02-27 18:16:14,541 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,541 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,542 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2022-02-27 18:16:14,543 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2022-02-27 18:16:14,543 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2022-02-27 18:16:14,543 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2022-02-27 18:16:14,544 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2022-02-27 18:16:14,544 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2022-02-27 18:16:14,545 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2022-02-27 18:16:14,545 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2022-02-27 18:16:14,545 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2022-02-27 18:16:14,546 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2022-02-27 18:16:14,547 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2022-02-27 18:16:14,548 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2022-02-27 18:16:14,548 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2022-02-27 18:16:14,549 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2022-02-27 18:16:14,549 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias\n",
      "2022-02-27 18:16:14,550 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight\n",
      "2022-02-27 18:16:17,994 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /var/folders/qr/8__6lqs525vbb3xk4c52jhxc0000gp/T/tmp6prr7m82\n"
     ]
    },
    {
     "ename": "ConfigurationError",
     "evalue": "Default implementation simple-influence is not registered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigurationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qr/8__6lqs525vbb3xk4c52jhxc0000gp/T/ipykernel_14476/2132424449.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mice/data/aclImdb/test/neg/4377_4.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mice/trained_predictors/imdb/model/model.tar.gz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msimple_if\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleInfluence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_reader_to_load\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImdbDatasetReader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msimple_if\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpret_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lecture_env/lib/python3.7/site-packages/allennlp/interpret/influence_interpreters/influence_interpreter.py\u001b[0m in \u001b[0;36mfrom_path\u001b[0;34m(cls, archive_path, interpreter_name, train_data_path, train_data_loader, test_data_loader, params_to_freeze, cuda_device, import_plugins, overrides, **extras)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mparams_to_freeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams_to_freeze\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mcuda_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcuda_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         )\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lecture_env/lib/python3.7/site-packages/allennlp/interpret/influence_interpreters/influence_interpreter.py\u001b[0m in \u001b[0;36mfrom_archive\u001b[0;34m(cls, archive, interpreter_name, train_data_path, train_data_loader, test_data_loader, params_to_freeze, cuda_device, **extras)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mother\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0mare\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0minterpreter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mby_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpreter_name\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_implementation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         return interpreter_cls(\n\u001b[1;32m    270\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lecture_env/lib/python3.7/site-packages/allennlp/common/registrable.py\u001b[0m in \u001b[0;36mby_name\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \"\"\"\n\u001b[1;32m    155\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"instantiating registered subclass {name} of {cls}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0msubclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstructor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_class_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconstructor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_RegistrableT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lecture_env/lib/python3.7/site-packages/allennlp/common/registrable.py\u001b[0m in \u001b[0;36mresolve_class_name\u001b[0;34m(cls, name)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;31m# is not a qualified class name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mavailable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0msuggestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_suggestion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             raise ConfigurationError(\n",
      "\u001b[0;32m~/miniconda3/envs/lecture_env/lib/python3.7/site-packages/allennlp/common/registrable.py\u001b[0m in \u001b[0;36mlist_available\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConfigurationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Default implementation {default} is not registered\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConfigurationError\u001b[0m: Default implementation simple-influence is not registered"
     ]
    }
   ],
   "source": [
    "from allennlp.interpret.influence_interpreters import SimpleInfluence\n",
    "from mice.src.predictors.imdb.imdb_dataset_reader import ImdbDatasetReader\n",
    "\n",
    "test_file = \"mice/data/aclImdb/test/neg/4377_4.txt\"\n",
    "archive = \"mice/trained_predictors/imdb/model/model.tar.gz\"\n",
    "simple_if = SimpleInfluence.from_path(archive, dataset_reader_to_load=ImdbDatasetReader)\n",
    "simple_if.interpret_from_file(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1298a7",
   "metadata": {},
   "source": [
    "## Contrastive Edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e64f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"mice/\")\n",
    "from src.utils import html_highlight_diffs\n",
    "from IPython.core.display import display, HTML\n",
    "import numpy as np\n",
    "from mice.src.utils import load_predictor, get_ints_to_labels\n",
    "\n",
    "TASK = \"imdb\"\n",
    "STAGE2EXP = \"mice_binary\"\n",
    "EDIT_PATH = f\"mice/results/{TASK}/edits/{STAGE2EXP}/edits.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc4c9746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_edits(path):\n",
    "    edits = pd.read_csv(EDIT_PATH, sep=\"\\t\", lineterminator=\"\\n\", error_bad_lines=False, warn_bad_lines=True)\n",
    "\n",
    "    if edits['new_pred'].dtype == pd.np.dtype('float64'):\n",
    "        edits['new_pred'] = edits.apply(lambda row: str(int(row['new_pred']) if not np.isnan(row['new_pred']) else \"\"), axis=1)\n",
    "        edits['orig_pred'] = edits.apply(lambda row: str(int(row['orig_pred']) if not np.isnan(row['orig_pred']) else \"\"), axis=1)\n",
    "        edits['contrast_pred'] = edits.apply(lambda row: str(int(row['contrast_pred']) if not np.isnan(row['contrast_pred']) else \"\"), axis=1)\n",
    "    else:\n",
    "        edits['new_pred'].fillna(value=\"\", inplace=True)\n",
    "        edits['orig_pred'].fillna(value=\"\", inplace=True)\n",
    "        edits['contrast_pred'].fillna(value=\"\", inplace=True)\n",
    "    return edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d24842de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_edits(edits):\n",
    "    \"\"\" MiCE writes all edits that are found in Stage 2, \n",
    "    but we only want to evaluate the smallest per input. \n",
    "    Calling get_sorted_e() \"\"\"\n",
    "    return edits[edits['sorted_idx'] == 0]\n",
    "    \n",
    "def evaluate_edits(edits):\n",
    "    temp = edits[edits['sorted_idx'] == 0]\n",
    "    minim = temp['minimality'].mean()\n",
    "    flipped = temp[temp['new_pred'].astype(str)==temp['contrast_pred'].astype(str)]\n",
    "    nunique = temp['data_idx'].nunique()\n",
    "    flip_rate = len(flipped)/nunique\n",
    "    duration=temp['duration'].mean()\n",
    "    metrics = {\n",
    "        \"num_total\": nunique,\n",
    "        \"num_flipped\": len(flipped),\n",
    "        \"flip_rate\": flip_rate,\n",
    "        \"minimality\": minim,\n",
    "        \"duration\": duration,\n",
    "    }\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k}: \\t{round(v, 3)}\")\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "475af814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_edits(row):\n",
    "    html_original, html_edited = html_highlight_diffs(row['orig_editable_seg'], row['edited_editable_seg'])\n",
    "    minim = round(row['minimality'], 3)\n",
    "    print(f\"MINIMALITY: \\t{minim}\")\n",
    "    print(\"\")\n",
    "    display(HTML(html_original))\n",
    "    display(HTML(html_edited))\n",
    "\n",
    "def display_classif_results(rows):\n",
    "    for _, row in rows.iterrows():\n",
    "        orig_contrast_prob_pred = round(row['orig_contrast_prob_pred'], 3)\n",
    "        new_contrast_prob_pred = round(row['new_contrast_prob_pred'], 3)\n",
    "        print(\"-----------------------\")\n",
    "        print(f\"ORIG LABEL: \\t{row['orig_pred']}\")\n",
    "        print(f\"CONTR LABEL: \\t{row['contrast_pred']} (Orig Pred Prob: {orig_contrast_prob_pred})\")\n",
    "        print(f\"NEW LABEL: \\t{row['new_pred']} (New Pred Prob: {new_contrast_prob_pred})\")\n",
    "        print(\"\")\n",
    "        display_edits(row)\n",
    "\n",
    "def display_race_results(rows):\n",
    "    for _, row in rows.iterrows():\n",
    "        orig_contrast_prob_pred = round(row['orig_contrast_prob_pred'], 3)\n",
    "        new_contrast_prob_pred = round(row['new_contrast_prob_pred'], 3)\n",
    "        orig_input = eval(row['orig_input'])\n",
    "        options = orig_input['options']\n",
    "        print(\"-----------------------\")\n",
    "        print(f\"QUESTION: {orig_input['question']}\")\n",
    "        print(\"\\nOPTIONS:\")\n",
    "        for opt_idx, opt in enumerate(options):\n",
    "            print(f\"  ({opt_idx}) {opt}\")\n",
    "        print(f\"\\nORIG LABEL: \\t{row['orig_pred']}\")\n",
    "        print(f\"CONTR LABEL: \\t{row['contrast_pred']} (Orig Pred Prob: {orig_contrast_prob_pred})\")\n",
    "        print(f\"NEW LABEL: \\t{row['new_pred']} (New Pred Prob: {new_contrast_prob_pred})\")\n",
    "        print(\"\")\n",
    "        display_edits(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b43ae50a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mice/results/imdb/edits/mice_binary/edits.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qr/8__6lqs525vbb3xk4c52jhxc0000gp/T/ipykernel_14618/2730029373.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0medits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_edits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEDIT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0medits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_best_edits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_edits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/qr/8__6lqs525vbb3xk4c52jhxc0000gp/T/ipykernel_14618/3139568612.py\u001b[0m in \u001b[0;36mread_edits\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_edits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0medits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEDIT_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlineterminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0medits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0medits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lecture_env/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lecture_env/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lecture_env/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lecture_env/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/lecture_env/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mice/results/imdb/edits/mice_binary/edits.csv'"
     ]
    }
   ],
   "source": [
    "edits = read_edits(EDIT_PATH)\n",
    "edits = get_best_edits(edits)\n",
    "metrics = evaluate_edits(edits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b16e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
